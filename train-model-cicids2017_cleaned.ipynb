{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13449477,"sourceType":"datasetVersion","datasetId":8536996}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/huudatlego/train-model-cicids2017-cleaned?scriptVersionId=284828571\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Cell 1: Import Thư viện và Load Dữ liệu**","metadata":{}},{"cell_type":"code","source":"# --- 1. IMPORT CÁC THƯ VIỆN CẦN THIẾT ---\nimport pandas as pd\nimport numpy as np\nimport joblib # Dùng để lưu mô hình\n\n# Thư viện của Scikit-learn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nprint(\"Các thư viện đã được import thành công!\")\n\n# --- 2. LOAD DỮ LIỆU SẠCH ---\n# Thay thế '/kaggle/input/cicids2017-cleaned-data/cicids2017_cleaned.csv' \n# bằng đường dẫn chính xác đến file của bạn sau khi add data.\ntry:\n    file_path = '/kaggle/input/cicids2017-cleaned-data/cicids2017_cleaned.csv'\n    df = pd.read_csv(file_path)\n    print(\"Đã tải thành công file dữ liệu sạch!\")\n    print(f\"Bộ dữ liệu có {df.shape[0]} dòng và {df.shape[1]} cột.\")\nexcept FileNotFoundError:\n    print(\"LỖI: Không tìm thấy file dữ liệu. Vui lòng kiểm tra lại đường dẫn file trong phần 'Add Input'.\")\n\n# Hiển thị 5 dòng đầu tiên để kiểm tra\ndf.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Cell 2: Chuẩn bị Dữ liệu cho Huấn luyện**","metadata":{}},{"cell_type":"code","source":"# --- 3. TÁCH BIẾN ĐỘC LẬP (X) VÀ BIẾN PHỤ THUỘC (y) ---\n# X là tất cả các cột trừ cột 'Attack Type'\nX = df.drop('Attack Type', axis=1)\n\n# y là cột 'Attack Type'\ny = df['Attack Type']\n\nprint(\"Đã tách X và y.\")\nprint(\"Số lượng đặc trưng (features) trong X:\", X.shape[1])\n\n# --- 4. MÃ HÓA NHÃN (LABEL ENCODING) ---\n# Chuyển các nhãn dạng chữ (ví dụ: 'Normal Traffic') thành số (ví dụ: 0, 1, 2...)\nle = LabelEncoder()\ny_encoded = le.fit_transform(y)\n\n# In ra để xem các lớp và mã số tương ứng\nprint(\"\\nCác lớp và mã số tương ứng:\")\nfor index, label in enumerate(le.classes_):\n    print(f\"{label}: {index}\")\n    \n# --- 5. CHIA DỮ LIỆU TRAIN/TEST (Tỷ lệ 70/30) ---\n# Chia dữ liệu để có tập huấn luyện và tập kiểm thử riêng biệt\n# stratify=y_encoded đảm bảo tỷ lệ các loại tấn công trong tập train và test là như nhau\nX_train, X_test, y_train, y_test = train_test_split(\n    X, \n    y_encoded, \n    test_size=0.3, \n    random_state=42, \n    stratify=y_encoded\n)\n\nprint(f\"\\nKích thước tập huấn luyện (train): {X_train.shape[0]} dòng\")\nprint(f\"Kích thước tập kiểm thử (test): {X_test.shape[0]} dòng\")\n\n# --- 6. SCALING DỮ LIỆU BẰNG STANDARDSCALER ---\n# Chuẩn hóa dữ liệu để các đặc trưng có cùng thang đo, giúp mô hình học tốt hơn\nscaler = StandardScaler()\n\n# Dùng fit_transform trên tập train để học các tham số scaling\nX_train_scaled = scaler.fit_transform(X_train)\n\n# Chỉ dùng transform trên tập test để áp dụng các tham số đã học từ tập train\nX_test_scaled = scaler.transform(X_test)\n\nprint(\"\\nĐã thực hiện scaling dữ liệu thành công!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**THÊM MỚI: THỰC HIỆN TINH CHỈNH SIÊU THAM SỐ (HYPERPARAMETER TUNING)**","metadata":{}},{"cell_type":"code","source":"### THÊM MỚI: THỰC HIỆN TINH CHỈNH SIÊU THAM SỐ (HYPERPARAMETER TUNING) ###\nfrom sklearn.model_selection import RandomizedSearchCV\n\nprint(\"Bắt đầu quá trình tìm kiếm siêu tham số tối ưu...\")\n\n# 1. Định nghĩa không gian tìm kiếm cho các tham số\nparam_distributions = {\n    'n_estimators': [100, 150],             # Thử số lượng cây\n    'max_depth': [None, 30, 50],            # Thử độ sâu tối đa\n    'min_samples_split': [2, 5],            # Thử số mẫu tối thiểu để chia\n    'min_samples_leaf': [1, 2]              # Thử số mẫu tối thiểu ở lá\n}\n\n# 2. Khởi tạo mô hình Random Forest cơ bản\nrf_base = RandomForestClassifier(random_state=42, n_jobs=-1)\n\n# 3. Thiết lập RandomizedSearchCV\n# n_iter=4: Sẽ thử 4 kết hợp ngẫu nhiên. Con số này nhỏ để chạy nhanh, bạn có thể tăng lên nếu có thời gian.\n# cv=3: Sử dụng 3-fold cross-validation để đánh giá mỗi kết hợp.\n# verbose=2: Hiển thị log chi tiết.\nrandom_search = RandomizedSearchCV(\n    estimator=rf_base,\n    param_distributions=param_distributions,\n    n_iter=4,  # <-- Tăng/giảm số lần thử tùy vào thời gian bạn có\n    cv=3,\n    verbose=2,\n    random_state=42,\n    n_jobs=-1\n)\n\n# 4. Chạy quá trình tìm kiếm trên một MẪU NHỎ của tập train để tiết kiệm thời gian\n# Lấy 5% dữ liệu train để chạy tuning\nX_train_sample = X_train_scaled[:int(len(X_train_scaled)*0.05)]\ny_train_sample = y_train[:int(len(y_train)*0.05)]\n\nrandom_search.fit(X_train_sample, y_train_sample)\n\n# 5. In ra kết quả\nprint(\"\\n...Tìm kiếm hoàn tất!\")\nprint(\"Các tham số tốt nhất tìm được là:\")\nprint(random_search.best_params_)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Cell 3: Huấn luyện và Đánh giá Mô hình Random Forest**","metadata":{}},{"cell_type":"code","source":"# --- 7. XÂY DỰNG VÀ HUẤN LUYỆN MÔ HÌNH VỚI THAM SỐ TỐT NHẤT ---\n\n# Lấy các tham số tốt nhất đã tìm được từ bước Randomized Search ở cell trước\n# Nếu bạn không chạy lại cell tuning, bạn có thể gán thủ công ở đây\n# Ví dụ: best_params = {'n_estimators': 150, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\ntry:\n    best_params = random_search.best_params_\nexcept NameError:\n    print(\"Biến 'random_search' không tồn tại. Sử dụng bộ tham số mặc định đã chọn.\")\n    best_params = {\n        'n_estimators': 100,\n        'max_depth': None,\n        'min_samples_split': 2,\n        'min_samples_leaf': 1\n    }\n\nprint(f\"Sử dụng các tham số sau để huấn luyện mô hình cuối cùng: {best_params}\\n\")\n\n\n# Khởi tạo mô hình Random Forest với các siêu tham số đã được TỐI ƯU HÓA\n# Toán tử **best_params sẽ tự động điền các giá trị từ dict vào\nrf_model_tuned = RandomForestClassifier(\n    **best_params,\n    random_state=42,\n    n_jobs=-1,\n    verbose=1\n)\n\n\n# --- 7.1. KIỂM ĐỊNH CHÉO LẦN NỮA VỚI MÔ HÌNH TỐI ƯU (Tùy chọn nhưng nên có) ---\n# Bước này để xác nhận lại sự ổn định của bộ tham số tốt nhất trên toàn bộ tập train\nfrom sklearn.model_selection import cross_val_score\nprint(\"Bắt đầu thực hiện Kiểm định chéo 5-fold trên mô hình đã tối ưu...\")\n# cv=5 nghĩa là chia tập train ra 5 phần\n# n_jobs=-1 để chạy song song, tăng tốc\ncv_scores = cross_val_score(rf_model_tuned, X_train_scaled, y_train, cv=5, n_jobs=-1, verbose=1)\nprint(\"\\n...Kiểm định chéo hoàn tất!\")\nprint(f\"--> Cross-Validation Scores của mô hình tối ưu: {cv_scores}\")\nprint(f\"--> Cross-Validation Mean Score: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\\n\")\n\n\n# --- 7.2. HUẤN LUYỆN MÔ HÌNH CUỐI CÙNG ---\nprint(\"Bắt đầu quá trình huấn luyện mô hình cuối cùng trên toàn bộ tập train...\")\n# Huấn luyện mô hình trên toàn bộ dữ liệu train đã được scaling\nrf_model_tuned.fit(X_train_scaled, y_train)\nprint(\"...Huấn luyện hoàn tất!\")\n\n\n# --- 8. ĐÁNH GIÁ HIỆU NĂNG MÔ HÌNH TRÊN TẬP TEST ---\nprint(\"\\nĐang thực hiện dự đoán trên tập kiểm thử...\")\n# Dùng mô hình đã huấn luyện để dự đoán trên tập test\ny_pred = rf_model_tuned.predict(X_test_scaled)\nprint(\"...Dự đoán hoàn tất!\")\n\n\n# --- 8.1. IN BÁO CÁO PHÂN LOẠI ---\nprint(\"\\nBáo cáo Phân loại (Classification Report) với 4 chữ số thập phân:\")\n# Thêm tham số digits=4 để có kết quả chi tiết\nprint(classification_report(y_test, y_pred, target_names=le.classes_, digits=4))\n\n\n# --- 8.2. VẼ MA TRẬN NHẦM LẪN ---\nprint(\"\\nMa trận Nhầm lẫn (Confusion Matrix):\")\ncm = confusion_matrix(y_test, y_pred)\n# Vẽ heatmap cho ma trận nhầm lẫn để dễ nhìn hơn\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\nplt.xlabel('Dự đoán (Predicted)')\nplt.ylabel('Thực tế (Actual)')\nplt.title('Confusion Matrix Heatmap')\nplt.show()\n\n\n# --- 8.3. IN ĐỘ CHÍNH XÁC TỔNG THỂ ---\n# Tính lại từ Ma trận Nhầm lẫn để có con số chính xác nhất\naccuracy_from_cm = np.trace(cm) / np.sum(cm)\nprint(f\"\\nĐộ chính xác tổng thể cuối cùng (tính từ Ma trận Nhầm lẫn): {accuracy_from_cm * 100:.4f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Cell 4: Lưu lại Mô hình và các Công cụ**","metadata":{}},{"cell_type":"code","source":"# --- 9. LƯU LẠI CÁC \"SẢN PHẨM\" ĐỂ TRIỂN KHAI ---\n# Tạo tên file\nmodel_filename = 'botnet_model.pkl'\nscaler_filename = 'scaler.pkl'\nencoder_filename = 'label_encoder.pkl'\n\n# Dùng joblib để lưu các đối tượng Python\n# SỬA LỖI: Thay 'rf_model' bằng 'rf_model_tuned'\njoblib.dump(rf_model_tuned, model_filename)\n\n# Hai dòng này đã đúng vì biến 'scaler' và 'le' được tạo ở Cell 2\njoblib.dump(scaler, scaler_filename)\njoblib.dump(le, encoder_filename)\n\nprint(f\"Đã lưu thành công 3 files vào thư mục /kaggle/working/:\")\nprint(f\"- Mô hình: {model_filename}\")\nprint(f\"- Scaler: {scaler_filename}\")\nprint(f\"- Label Encoder: {encoder_filename}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}