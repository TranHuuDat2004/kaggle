{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13449477,"sourceType":"datasetVersion","datasetId":8536996}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/huudatlego/train-model-cicids2017-cleaned?scriptVersionId=269608983\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-21T04:50:50.984951Z","iopub.execute_input":"2025-10-21T04:50:50.985336Z","iopub.status.idle":"2025-10-21T04:50:51.365213Z","shell.execute_reply.started":"2025-10-21T04:50:50.9853Z","shell.execute_reply":"2025-10-21T04:50:51.363511Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Cell 1: Import Thư viện và Load Dữ liệu**","metadata":{}},{"cell_type":"code","source":"# --- 1. IMPORT CÁC THƯ VIỆN CẦN THIẾT ---\nimport pandas as pd\nimport numpy as np\nimport joblib # Dùng để lưu mô hình\n\n# Thư viện của Scikit-learn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nprint(\"Các thư viện đã được import thành công!\")\n\n# --- 2. LOAD DỮ LIỆU SẠCH ---\n# Thay thế '/kaggle/input/cicids2017-cleaned-data/cicids2017_cleaned.csv' \n# bằng đường dẫn chính xác đến file của bạn sau khi add data.\ntry:\n    file_path = '/kaggle/input/cicids2017-cleaned-data/cicids2017_cleaned.csv'\n    df = pd.read_csv(file_path)\n    print(\"Đã tải thành công file dữ liệu sạch!\")\n    print(f\"Bộ dữ liệu có {df.shape[0]} dòng và {df.shape[1]} cột.\")\nexcept FileNotFoundError:\n    print(\"LỖI: Không tìm thấy file dữ liệu. Vui lòng kiểm tra lại đường dẫn file trong phần 'Add Input'.\")\n\n# Hiển thị 5 dòng đầu tiên để kiểm tra\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T04:50:51.367665Z","iopub.execute_input":"2025-10-21T04:50:51.368286Z","iopub.status.idle":"2025-10-21T04:51:15.095613Z","shell.execute_reply.started":"2025-10-21T04:50:51.368251Z","shell.execute_reply":"2025-10-21T04:51:15.094604Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Cell 2: Chuẩn bị Dữ liệu cho Huấn luyện**","metadata":{}},{"cell_type":"code","source":"# --- 3. TÁCH BIẾN ĐỘC LẬP (X) VÀ BIẾN PHỤ THUỘC (y) ---\n# X là tất cả các cột trừ cột 'Attack Type'\nX = df.drop('Attack Type', axis=1)\n\n# y là cột 'Attack Type'\ny = df['Attack Type']\n\nprint(\"Đã tách X và y.\")\nprint(\"Số lượng đặc trưng (features) trong X:\", X.shape[1])\n\n# --- 4. MÃ HÓA NHÃN (LABEL ENCODING) ---\n# Chuyển các nhãn dạng chữ (ví dụ: 'Normal Traffic') thành số (ví dụ: 0, 1, 2...)\nle = LabelEncoder()\ny_encoded = le.fit_transform(y)\n\n# In ra để xem các lớp và mã số tương ứng\nprint(\"\\nCác lớp và mã số tương ứng:\")\nfor index, label in enumerate(le.classes_):\n    print(f\"{label}: {index}\")\n    \n# --- 5. CHIA DỮ LIỆU TRAIN/TEST (Tỷ lệ 70/30) ---\n# Chia dữ liệu để có tập huấn luyện và tập kiểm thử riêng biệt\n# stratify=y_encoded đảm bảo tỷ lệ các loại tấn công trong tập train và test là như nhau\nX_train, X_test, y_train, y_test = train_test_split(\n    X, \n    y_encoded, \n    test_size=0.3, \n    random_state=42, \n    stratify=y_encoded\n)\n\nprint(f\"\\nKích thước tập huấn luyện (train): {X_train.shape[0]} dòng\")\nprint(f\"Kích thước tập kiểm thử (test): {X_test.shape[0]} dòng\")\n\n# --- 6. SCALING DỮ LIỆU BẰNG STANDARDSCALER ---\n# Chuẩn hóa dữ liệu để các đặc trưng có cùng thang đo, giúp mô hình học tốt hơn\nscaler = StandardScaler()\n\n# Dùng fit_transform trên tập train để học các tham số scaling\nX_train_scaled = scaler.fit_transform(X_train)\n\n# Chỉ dùng transform trên tập test để áp dụng các tham số đã học từ tập train\nX_test_scaled = scaler.transform(X_test)\n\nprint(\"\\nĐã thực hiện scaling dữ liệu thành công!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T04:51:15.096661Z","iopub.execute_input":"2025-10-21T04:51:15.097018Z","iopub.status.idle":"2025-10-21T04:51:20.505566Z","shell.execute_reply.started":"2025-10-21T04:51:15.096987Z","shell.execute_reply":"2025-10-21T04:51:20.504119Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Cell 3: Huấn luyện và Đánh giá Mô hình Random Forest**","metadata":{}},{"cell_type":"code","source":"# --- 7. XÂY DỰNG VÀ HUẤN LUYỆN MÔ HÌNH RANDOM FOREST ---\n# Khởi tạo mô hình với các tham số cơ bản\n# n_jobs=-1 sẽ sử dụng tất cả các nhân CPU có sẵn để tăng tốc độ huấn luyện\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, verbose=1)\n\n\n### THÊM MỚI: THỰC HIỆN KIỂM ĐỊNH CHÉO (CROSS-VALIDATION) ###\nfrom sklearn.model_selection import cross_val_score\nprint(\"Bắt đầu thực hiện Kiểm định chéo 5-fold trên tập huấn luyện...\")\n# cv=5 nghĩa là chia tập train ra 5 phần\n# n_jobs=-1 để chạy song song, tăng tốc\ncv_scores = cross_val_score(rf_model, X_train_scaled, y_train, cv=5, n_jobs=-1)\nprint(\"...Kiểm định chéo hoàn tất!\")\nprint(f\"--> Cross-Validation Scores: {cv_scores}\")\nprint(f\"--> Cross-Validation Mean Score: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\\n\")\n\n\nprint(\"Bắt đầu quá trình huấn luyện mô hình Random Forest trên toàn bộ tập train...\")\n# Huấn luyện mô hình trên dữ liệu đã được scaling\nrf_model.fit(X_train_scaled, y_train)\nprint(\"...Huấn luyện hoàn tất!\")\n\n\n# --- 8. ĐÁNH GIÁ HIỆU NĂNG MÔ HÌNH ---\nprint(\"\\nĐang thực hiện dự đoán trên tập kiểm thử...\")\n# Dùng mô hình đã huấn luyện để dự đoán trên tập test\ny_pred = rf_model.predict(X_test_scaled)\nprint(\"...Dự đoán hoàn tất!\")\n\n\n### CẬP NHẬT: In báo cáo với 4 chữ số thập phân ###\nprint(\"\\nBáo cáo Phân loại (Classification Report) với 4 chữ số thập phân:\")\n# Thêm tham số digits=4\nprint(classification_report(y_test, y_pred, target_names=le.classes_, digits=4))\n\n\n# In ma trận nhầm lẫn (Confusion Matrix)\nprint(\"\\nMa trận Nhầm lẫn (Confusion Matrix):\")\ncm = confusion_matrix(y_test, y_pred)\n# Vẽ heatmap cho ma trận nhầm lẫn để dễ nhìn hơn\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\nplt.xlabel('Dự đoán (Predicted)')\nplt.ylabel('Thực tế (Actual)')\nplt.title('Confusion Matrix Heatmap')\nplt.show()\n\n# In độ chính xác tổng thể (tính lại từ cm để chắc chắn)\naccuracy_from_cm = np.trace(cm) / np.sum(cm)\nprint(f\"\\nĐộ chính xác tổng thể (tính từ Ma trận Nhầm lẫn): {accuracy_from_cm * 100:.4f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T04:51:20.507142Z","iopub.execute_input":"2025-10-21T04:51:20.50762Z","iopub.status.idle":"2025-10-21T04:57:26.324535Z","shell.execute_reply.started":"2025-10-21T04:51:20.507592Z","shell.execute_reply":"2025-10-21T04:57:26.322952Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Cell 4: Lưu lại Mô hình và các Công cụ**","metadata":{}},{"cell_type":"code","source":"# --- 9. LƯU LẠI CÁC \"SẢN PHẨM\" ĐỂ TRIỂN KHAI ---\n# Tạo tên file\nmodel_filename = 'botnet_model.pkl'\nscaler_filename = 'scaler.pkl'\nencoder_filename = 'label_encoder.pkl'\n\n# Dùng joblib để lưu các đối tượng Python\njoblib.dump(rf_model, model_filename)\njoblib.dump(scaler, scaler_filename)\njoblib.dump(le, encoder_filename)\n\nprint(f\"Đã lưu thành công 3 files vào thư mục /kaggle/working/:\")\nprint(f\"- Mô hình: {model_filename}\")\nprint(f\"- Scaler: {scaler_filename}\")\nprint(f\"- Label Encoder: {encoder_filename}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T04:57:26.326335Z","iopub.execute_input":"2025-10-21T04:57:26.326611Z","iopub.status.idle":"2025-10-21T04:57:26.416544Z","shell.execute_reply.started":"2025-10-21T04:57:26.326589Z","shell.execute_reply":"2025-10-21T04:57:26.4156Z"}},"outputs":[],"execution_count":null}]}